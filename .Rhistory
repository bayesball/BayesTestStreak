get.abbrev <- function(fname, lname){
as.character(subset(rosters,
First.Name==fname & Last.Name==lname)$Player.ID[1])
}
get.abbrev("Domonic", "Brown")
d <- subset(pbp.00.13, BAT_ID==player.id &
Season==season & AB_FL==TRUE)
player.id="browd004"
d <- subset(pbp.00.13, BAT_ID==player.id &
Season==season & AB_FL==TRUE)
season=2013
d <- subset(pbp.00.13, BAT_ID==player.id &
Season==season & AB_FL==TRUE)
d <- d[order(d$Date), ]
as.numeric(d$EVENT_CD==23) -> s
s
sum(s)
spacings(s)
get.spacings(s)
find.spacings(s)
s <- get.hr.sequence("Domonic", "Brown", 2013)
s
bayes.factor.function(s)
bayes.factor.function(s, plot=TRUE)
plot(find.spacings(s)$y)
geometric.plot(find.spacings(s)$y)
`4.11.2014` <- read.csv("~/Dropbox/ASA/JQAS/4.11.2014.csv")
View(`4.11.2014`)
names(4.11.2014)
jqas4.11.2014 <- read.csv("~/Dropbox/ASA/JQAS/jqas4.11.2014.csv")
View(jqas4.11.2014)
table(jqas4.11.2014$Document.Status.Id)
table(jqas4.11.2014$Status)
library(BayesTestStreak)
library(BayesTestStreak)
install.packages("ggplot2")
install.packages("LearnBayes")
library(BayesTestStreak)
setwd("~/Dropbox/COURSES/7580 Rfiles/montecarlo")
dist
folly(dexp, 1, 20, 0.1, 0.1)
folly <- function(rdist, mu0, alpha.t, alpha.g.g, m){
# Monte Carlo simulation of prob(Type I) error for Schucany and Ng paper
n1 <- 0       # count of number of samples that pass normality test
nreject <- 0  # number of rejections
for (i in 1:m){
y <- rdist(n)		    	# simulate exponential data
s <- shapiro.test(y)		# initial normality test on data
if(s$p.value > alpha.g){	# if you fail to reject ...
n1 <- n1 + 1
Tstat <- (mean(y) - mu0) / (sd(y) / sqrt(n))
nreject <- nreject + (abs(T) > qt(1 - alpha.t / 2, n - 1))
}
}
p <- nreject / n1  # estimate of (conditional) Type I error
se <- sqrt(p * (1 - p) / n1)
return(list(p=p, se=se))
}
folly(dexp, 1, 20, 0.1, 0.1)
folly <- function(rdist, mu0, n, alpha.t, alpha.g.g, m){
# Monte Carlo simulation of prob(Type I) error for Schucany and Ng paper
n1 <- 0       # count of number of samples that pass normality test
nreject <- 0  # number of rejections
for (i in 1:m){
y <- rdist(n)		    	# simulate exponential data
s <- shapiro.test(y)		# initial normality test on data
if(s$p.value > alpha.g){	# if you fail to reject ...
n1 <- n1 + 1
Tstat <- (mean(y) - mu0) / (sd(y) / sqrt(n))
nreject <- nreject + (abs(T) > qt(1 - alpha.t / 2, n - 1))
}
}
p <- nreject / n1  # estimate of (conditional) Type I error
se <- sqrt(p * (1 - p) / n1)
return(list(p=p, se=se))
}
folly(dexp, 1, 20, 0.1, 0.1, 1000)
folly <- function(rdist, mu0, n, alpha.t, alpha.g, m){
# Monte Carlo simulation of prob(Type I) error for Schucany and Ng paper
n1 <- 0       # count of number of samples that pass normality test
nreject <- 0  # number of rejections
for (i in 1:m){
y <- rdist(n)		    	# simulate exponential data
s <- shapiro.test(y)		# initial normality test on data
if(s$p.value > alpha.g){	# if you fail to reject ...
n1 <- n1 + 1
Tstat <- (mean(y) - mu0) / (sd(y) / sqrt(n))
nreject <- nreject + (abs(T) > qt(1 - alpha.t / 2, n - 1))
}
}
p <- nreject / n1  # estimate of (conditional) Type I error
se <- sqrt(p * (1 - p) / n1)
return(list(p=p, se=se))
}
folly(dexp, 1, 20, 0.1, 0.1, 1000)
library(LearnBayes)
laplace
rwmetrop
folly <- function(rdist, mu0, n, alpha.t, alpha.g, m){
# Monte Carlo simulation of prob(Type I) error for Schucany and Ng paper
n1 <- 0       # count of number of samples that pass normality test
nreject <- 0  # number of rejections
for (i in 1:m){
y <- rexp(n)		    	# simulate exponential data
s <- shapiro.test(y)		# initial normality test on data
if(s$p.value > alpha.g){	# if you fail to reject ...
n1 <- n1 + 1
Tstat <- (mean(y) - mu0) / (sd(y) / sqrt(n))
nreject <- nreject + (abs(T) > qt(1 - alpha.t / 2, n - 1))
}
}
p <- nreject / n1  # estimate of (conditional) Type I error
se <- sqrt(p * (1 - p) / n1)
return(list(p=p, se=se))
}
folly(dexp, 1, 20, 0.1, 0.1, 1000)
y <- rexp(n)		    	# simulate exponential data
n=20
y <- rexp(n)		    	# simulate exponential data
s <- shapiro.test(y)		# initial normality test on data
s
names(s)
folly <- function(mu0, n, alpha.t, alpha.g, m){
# Monte Carlo simulation of prob(Type I) error for Schucany and Ng paper
# exponential data case
n1 <- 0       # count of number of samples that pass normality test
nreject <- 0  # number of rejections
for (i in 1:m){
y <- rexp(n)		      	  # simulate exponential data
s <- shapiro.test(y)		  # initial normality test on data
if(s$p.value > alpha.g){	# if you fail to reject ...
n1 <- n1 + 1
Tstat <- (mean(y) - mu0) / (sd(y) / sqrt(n))
nreject <- nreject + (abs(T) > qt(1 - alpha.t / 2, n - 1))
}
}
p <- nreject / n1         # estimate of (conditional) Type I error
se <- sqrt(p * (1 - p) / n1)
return(list(p=p, se=se))
}
folly(1, 20, 0.1, 0.1, 1000)
?rexp
folly <- function(mu0, n, alpha.t, alpha.g, m){
# Monte Carlo simulation of prob(Type I) error for Schucany and Ng paper
# exponential data case
n1 <- 0       # count of number of samples that pass normality test
nreject <- 0  # number of rejections
for (i in 1:m){
y <- rexp(n, rate=mu0)		      	  # simulate exponential data
s <- shapiro.test(y)		            # initial normality test on data
if(s$p.value > alpha.g){	# if you fail to reject ...
n1 <- n1 + 1
Tstat <- (mean(y) - mu0) / (sd(y) / sqrt(n))
nreject <- nreject + (abs(T) > qt(1 - alpha.t / 2, n - 1))
}
}
p <- nreject / n1         # estimate of (conditional) Type I error
se <- sqrt(p * (1 - p) / n1)
return(list(p=p, se=se))
}
folly(1, 20, 0.1, 0.1, 10000)
alpha.g=.2
alpha.t=.2
n-20
n=20
n1 <- 0       # count of number of samples that pass normality test
nreject <- 0  # number of rejections
for (i in 1:m){
y <- rexp(n, rate=mu0)		      	  # simulate exponential data
s <- shapiro.test(y)		            # initial normality test on data
if(s$p.value > alpha.g){	# if you fail to reject ...
n1 <- n1 + 1
Tstat <- (mean(y) - mu0) / (sd(y) / sqrt(n))
nreject <- nreject + (abs(T) > qt(1 - alpha.t / 2, n - 1))
}
}
m=1000
n1 <- 0       # count of number of samples that pass normality test
nreject <- 0  # number of rejections
for (i in 1:m){
y <- rexp(n, rate=mu0)		      	  # simulate exponential data
s <- shapiro.test(y)		            # initial normality test on data
if(s$p.value > alpha.g){	# if you fail to reject ...
n1 <- n1 + 1
Tstat <- (mean(y) - mu0) / (sd(y) / sqrt(n))
nreject <- nreject + (abs(T) > qt(1 - alpha.t / 2, n - 1))
}
}
mu0=1
n1 <- 0       # count of number of samples that pass normality test
nreject <- 0  # number of rejections
for (i in 1:m){
y <- rexp(n, rate=mu0)		      	  # simulate exponential data
s <- shapiro.test(y)		            # initial normality test on data
if(s$p.value > alpha.g){	# if you fail to reject ...
n1 <- n1 + 1
Tstat <- (mean(y) - mu0) / (sd(y) / sqrt(n))
nreject <- nreject + (abs(T) > qt(1 - alpha.t / 2, n - 1))
}
}
nreject
n1
m
s$p.value
n
hist(y)
library(BayesTestStreak)
remove.packages("BayesTestSpacings", lib="~/Library/R/3.1/library")
find.spacings(c(1,0,0,1,1,1,0,0,1,0))
y <- rgeom(500, .3)
s <- find.spacings(y)$y
s
geometric.plot(s)
y <- rgeom(5000, .3)
s
s <- find.spacings(y)$y
geometric.plot(s)
y <- rgeom(500, .3)
s <- find.spacings(y)$y
geometric.plot(s)
setwd("~/Desktop/PGP Folder/STREAK")
source("get.hit.sequence2.R")
y <- get.hit.sequence2("Derek","Jeter", 2004)
source("get.hit.sequence2.R")
y <- get.hit.sequence2("Derek","Jeter", 2004)
load("~/Desktop/PGP Folder/STREAK/pbp.1960.1979.Rdata")
load("~/Desktop/PGP Folder/STREAK/pbp.1980.1999.Rdata")
load("~/Desktop/PGP Folder/STREAK/pbp.2000.2013.Rdata")
y <- get.hit.sequence2("Derek","Jeter", 2004)
load("~/Desktop/PGP Folder/STREAK/All.Rosters.Rdata")
y <- get.hit.sequence2("Derek","Jeter", 2004)
find.spacings(y)
bayes.factor.K(y, 5)
seasons <- 1996:2012
D <- NULL
for (j in seasons){
D <- rbind(D,
data.frame(Season=j,
y=get.hit.sequence2("Derek", "Jeter", j)))
print(j)
}
head(D)
library(Lahman)
d <- subset(Master, lastName=="Jeter")
names(Master)
d <- subset(Master, nameLast=="Jeter" & nameFirst=="Derek")
d
jeter <- subset(Batting, playerID=="jeterde01 ")
jeter
jeter <- subset(Batting, playerID=="jeterde01")
jeter
jeter1 <- subset(jeter, yearID>=1996 & yearID <- 2012)
jeter1 <- subset(jeter, yearID>=1996 & yearID <= 2012)
dim(jeter1)
with(jeter1, sum(AB))
with(jeter1, sum(H))
dim(D)
sum(D$y)
D[1:5,]
s <- get.spacings(D$y)
library(BayesTestStreak)
s <- get.spacings(D$y)
s <- find.spacings(D$y)
names(s)
max(s$y)
geometric.plot(s$y)
permutation.test(D$y)
bayes.factor.function(D$y)
bayes.factor.function(D$y, plot=TRUE)
table(s$y)
seasons <- 1996:2012
D2 <- NULL
for (j in seasons){
D2 <- rbind(D2,
data.frame(Season=j,
y=get.hr.sequence2("Derek", "Jeter", j)))
print(j)
}
source("get.hr.sequence2.R")
seasons <- 1996:2012
D2 <- NULL
for (j in seasons){
D2 <- rbind(D2,
data.frame(Season=j,
y=get.hr.sequence2("Derek", "Jeter", j)))
print(j)
}
s <- find.spacings(D$y)
max(s$y)
s <- find.spacings(D2$y)
max(s$y)
geometric.plot(s$y)
permutation.test(D2$y)
bayes.factor.function(D2$y, plot=TRUE)
table(s)
table(s$y)
library(Lahman)
library(ggplot2)
library(dplyr)
strikeouts <- summarize(group_by(Batting, yearID),
SO=sum(SO),
AB=sum(AB))
head(strikeouts)
ggplot(strikeouts, aes(yearID, SO / AB)) +
geom_point() + geom_smooth()
strikeouts
View(strikeouts)
strikeouts <- summarize(group_by(Batting, yearID),
SO=sum(SO, na.rm=TRUE),
AB=sum(AB, na.rm=TRUE))
ggplot(strikeouts, aes(yearID, SO / AB)) +
geom_point() + geom_smooth()
ggplot(strikeouts, aes(yearID, SO / AB)) +
geom_point() + geom_smooth(span=0.1)
strikeouts.60 <- filter(strikeouts, yearID >= 1960)
ggplot(strikeouts.60, aes(yearID, SO / AB)) +
geom_point() + geom_smooth(span=0.1)
ggplot(strikeouts.60, aes(yearID, SO / AB)) +
geom_point() + geom_smooth(span=0.3)
ggplot(strikeouts.60, aes(yearID, SO / AB)) +
geom_point() + geom_smooth(span=0.3) +
title("STRIKEOUT RATES 1960 - 2013")
ggplot(strikeouts.60, aes(yearID, SO / AB)) +
geom_point() + geom_smooth(span=0.3) +
title("STRIKEOUT RATES 1960 - 2013")
ggplot(strikeouts.60, aes(yearID, SO / AB)) +
geom_point() + geom_smooth(span=0.3) +
labs(title="STRIKEOUT RATES 1960 - 2013")
library(Lahman)
library(ggplot2)
library(dplyr)
strikeouts <- summarize(group_by(Batting, yearID),
SO=sum(SO, na.rm=TRUE),
AB=sum(AB, na.rm=TRUE))
strikeouts.60 <- filter(strikeouts, yearID >= 1960)
ggplot(strikeouts.60, aes(yearID, SO / AB)) +
geom_point() + geom_smooth(span=0.3) +
labs(title="STRIKEOUT RATES 1960 - 2013")
tail(strikeouts)
strikeouts$SO.Rate <- mutate(strikeouts, SO / AB)
ggplot(strikeouts.60, aes(yearID, SO.Rate)) +
geom_point() + geom_smooth(span=0.3) +
labs(title="STRIKEOUT RATES 1960 - 2013")
strikeouts$SO.Rate <- mutate(strikeouts, SO / AB)
?mutate
strikeouts <- mutate(strikeouts, SO.Rate = SO / AB)
mutate(strikeouts, SO.Rate = SO / AB)
strikeouts <- summarize(group_by(Batting, yearID),
SO=sum(SO, na.rm=TRUE),
AB=sum(AB, na.rm=TRUE))
mutate(strikeouts, SO.Rate = SO / AB)
strikeouts.60 <- filter(strikeouts, yearID >= 1960)
ggplot(strikeouts.60, aes(yearID, SO.Rate)) +
geom_point() + geom_smooth(span=0.3) +
labs(title="STRIKEOUT RATES 1960 - 2013")
strikeouts <- mutate(strikeouts, SO.Rate = SO / AB)
strikeouts.60 <- filter(strikeouts, yearID >= 1960)
ggplot(strikeouts.60, aes(yearID, SO.Rate)) +
geom_point() + geom_smooth(span=0.3) +
labs(title="STRIKEOUT RATES 1960 - 2013")
tail(strikeouts.60)
35902/159081
install.packages("rmarkdown")
columbia.gas.bills <- read.csv("~/Dropbox/COURSES/EDA 2014/NEW 2014/columbia.gas.bills.csv")
View(columbia.gas.bills)
str(columbia.gas.bills)
?factor
columbia.gas.bills$Month <- factor(columbia.gas.bills$Month,)
columbia.gas.bills$Month <- factor(columbia.gas.bills$Month,
levels=c("Jan","Feb","Mar","Apr","May","Jun","July","Aug","Sep","Oct",
"Nov","Dec"))
library(LearnEDA)
with(columbia.gas.bills, spread.level.plot(Bill, Month))
with(columbia.gas.bills, slider.compar(Bill, Month))
with(columbia.gas.bills, slider.compare(Bill, Month))
with(columbia.gas.bills, slider.power(Bill))
ln(179)
loge(179)
log(179)
log(94.28)-log(40.19)
exp(.85)
install.packages(c("devtools", "maps", "repmis", "testthat"))
setwd("~/Desktop/gamelogs")
get.data <- function(Season){
filename <- paste("gamelogs/gl",year,".txt", sep="")
d <- read.csv(filename, header=FALSE)
headers <- read.csv("gamelogs/game_log_header.csv")
names(d) <- names(headers)
d$Season <- substr(data$Date, 1, 4)
d
}
d <- get.data(1980)
get.data <- function(year){
filename <- paste("gamelogs/gl",year,".txt", sep="")
d <- read.csv(filename, header=FALSE)
headers <- read.csv("gamelogs/game_log_header.csv")
names(d) <- names(headers)
d$Season <- substr(data$Date, 1, 4)
d
}
d <- get.data(1980)
get.data <- function(year){
filename <- paste("gamelogs/gl",year,".txt", sep="")
d <- read.csv(filename, header=FALSE)
headers <- read.csv("gamelogs/game_log_header.csv")
names(d) <- names(headers)
d$Season <- substr(d$Date, 1, 4)
d
}
d <- get.data(1980)
names(d)
View(d)
get.data <- function(Seasons){
D <- NULL
for(year in Seasons){
filename <- paste("gamelogs/gl",year,".txt", sep="")
d <- read.csv(filename, header=FALSE)
headers <- read.csv("gamelogs/game_log_header.csv")
names(d) <- names(headers)
D <- rbind(D, d)
}
D$Season <- substr(D$Date, 1, 4)
D
}
d <- get.data(1980:1990)
table(d$Season)
d <- get.data(1964:2013)
table(d$Date)
table(d$Season)
library(dplyr)
names(d)
S <- summarize(group_by(D, Season),
Avg.Time <- mean(Duration))
S <- summarize(group_by(D, Season),
Avg.Time = mean(Duration))
library(dplyr)
S <- summarize(group_by(D, Season),
Avg.Time = mean(Duration))
S <- summarize(group_by(D, Season),
Avg.Time = mean(duration))
S <- summarize(group_by(d, Season),
Avg.Time = mean(duration))
S <- summarize(group_by(d, Season),
Avg.Time = mean(Duration))
head(S)
library(ggplot2)
ggplot(S, aes(Season, Avg.Time)) + geom_point() + geom_smooth()
S$Season <- as.numeric(S$Season)
ggplot(S, aes(Season, Avg.Time)) + geom_point() + geom_smooth()
ggplot(S, aes(Season, Avg.Time)) +
geom_point() + geom_smooth(span=.2)
ggplot(S, aes(Season, Avg.Time)) +
geom_point() + geom_smooth(span=.25)
S
?mean
S <- summarize(group_by(d, Season),
Avg.Time = mean(Duration, na.rm=TRUE))
library(ggplot2)
S$Season <- as.numeric(S$Season)
ggplot(S, aes(Season, Avg.Time)) +
geom_point() + geom_smooth(span=.25)
library(LearnEDA)
?slider.match
slider.match(rchisq(100,df=4))
slider.match
columbia.gas.bills <- read.csv("~/Dropbox/COURSES/EDA 2014/NEW 2014/columbia.gas.bills.csv")
View(columbia.gas.bills)
library(LearnEDA)
slider.match(columbia.gas.bills$Bill)
slider.match(columbia.gas.bills$Bill)
library(LearnEDA)
slider.match
getwd()
dir()
devtools::load_all(".")
library(BayesTestStreak)
library(BayesTestStreak)
y <- c(0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0)
bayes.factor.function(y)
library(BayesTestStreak)
y <- rbinom(100, size=1, p=.3)
bayes.factor.K(y, 5)
library(BayesTestStreak)
library(BayesTestStreak)
y <- c(0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0)
find.spacings(y)
x <- rgeom(200, size=1, prob=0.5)
s <- find.spacings(x)
geometric.plot(s$y)
x <- rgeom(200, prob=0.5)
s <- find.spacings(x)
geometric.plot(s$y)
x <- rgeom(500, prob=0.5)
s <- find.spacings(x)
geometric.plot(s$y)
library(BayesTestStreak)
library(BayesTestStreak)
rep(1, 3)
y <- rbinom(10, size=500,
prob=c(rep(0.1, 3), rep(0.3, 4), rep(0.5, 3)))
data <- rbind(y, 500)
y <- rbinom(10, size=500,
prob=c(rep(0.1, 3), rep(0.3, 4), rep(0.5, 3)))
data <- rbind(y, 500)
pred.simulation.K(data, 5)
data
data
y <- rbinom(10, size=500,
prob=c(rep(0.1, 3), rep(0.3, 4), rep(0.5, 3)))
data <- cbind(y, 500)
pred.simulation.K(data, 5)
library(BayesTestStreak)
